{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_network.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/wileyw/DeepLearningDemos/blob/master/SiameseNetwork/siamese_network.ipynb",
      "authorship_tag": "ABX9TyP0itjOvku+a1woxEryhXpt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wileyw/DeepLearningDemos/blob/master/SiameseNetwork/siamese_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js4124anRYJO"
      },
      "source": [
        "# Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwjtWmOdRQeR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icUAqOYASn_k"
      },
      "source": [
        "# !unzip drive/MyDrive/fruits-360.zip -d drive/MyDrive\n",
        "# https://towardsdatascience.com/siamese-networks-line-by-line-explanation-for-beginners-55b8be1d2fc6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-HIe5dlT75I"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRkoqpVGUV4Q"
      },
      "source": [
        "!ls /content/drive\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-aRHmZaXYkm"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dbmTg1XdUa"
      },
      "source": [
        "base_dir = r'/content/drive/MyDrive/fruits-360/Training/'\n",
        "train_test_split = 0.7\n",
        "no_of_files_in_each_class = 10\n",
        "\n",
        "#Read all the folders in the directory\n",
        "folder_list = os.listdir(base_dir)\n",
        "print( len(folder_list), \"categories found in the dataset\")\n",
        "\n",
        "#Declare training array\n",
        "cat_list = []\n",
        "x = []\n",
        "y = []\n",
        "y_label = 0\n",
        "\n",
        "#Using just no_of_files_in_each_class images per category\n",
        "for folder_name in folder_list:\n",
        "    files_list = os.listdir(os.path.join(base_dir, folder_name))\n",
        "    if len(files_list) < no_of_files_in_each_class:\n",
        "      print(f\"skipping {folder_name}\")\n",
        "      continue\n",
        "    temp=[]\n",
        "    for file_name in files_list[:no_of_files_in_each_class]:\n",
        "        temp.append(len(x))\n",
        "        x.append(np.asarray(Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB').resize((100, 100))))\n",
        "        y.append(y_label)\n",
        "    y_label+=1\n",
        "    cat_list.append(temp)\n",
        "\n",
        "cat_list = np.asarray(cat_list)\n",
        "x = np.asarray(x)/255.0\n",
        "y = np.asarray(y)\n",
        "print('X, Y shape',x.shape, y.shape, cat_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITHz55FNf4fC"
      },
      "source": [
        "# print(np.asarray(Image.open(\"/content/drive/MyDrive/fruits-360/Training/Apple Braeburn/r_289_100.jpg\").convert('RGB').resize((100, 100))))\n",
        "# print(\"test\")\n",
        "plt.imshow(np.asarray(Image.open(\"/content/drive/MyDrive/fruits-360/Training/Apple Braeburn/r_289_100.jpg\").convert('RGB').resize((100, 100)))/255.)\n",
        "# im = Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfdur2NiUyD"
      },
      "source": [
        "x = x.transpose(0, 3, 1, 2)\n",
        "print('X, Y shape',x.shape, y.shape, cat_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhS_zspMYXyb"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIRD6DN3YPyA"
      },
      "source": [
        "train_size = int(len(folder_list)*train_test_split)\n",
        "test_size = len(folder_list) - train_size\n",
        "print(train_size, 'classes for training and', test_size, ' classes for testing')\n",
        "\n",
        "train_files = train_size * no_of_files_in_each_class\n",
        "\n",
        "#Training Split\n",
        "x_train = x[:train_files]\n",
        "y_train = y[:train_files]\n",
        "cat_train = cat_list[:train_size]\n",
        "\n",
        "#Validation Split\n",
        "x_val = x[train_files:]\n",
        "y_val = y[train_files:]\n",
        "cat_test = cat_list[train_size:]\n",
        "\n",
        "print('X&Y shape of training data :',x_train.shape, 'and', y_train.shape, cat_train.shape)\n",
        "print('X&Y shape of testing data :' , x_val.shape, 'and', y_val.shape, cat_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgjt2L-RqUOs"
      },
      "source": [
        "# plt.imshow(x[30].transpose(1,2,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuACgkS4YlhM"
      },
      "source": [
        "## Generating Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k-slYI3Yo2D"
      },
      "source": [
        "def get_batch(batch_size=64):\n",
        "    \n",
        "    temp_x = x_train\n",
        "    temp_cat_list = cat_train\n",
        "    start=0\n",
        "    end=train_size\n",
        "    batch_x=[]\n",
        "        \n",
        "    batch_y = np.zeros(batch_size)\n",
        "    batch_y[int(batch_size/2):] = 1\n",
        "    np.random.shuffle(batch_y)\n",
        "    \n",
        "    class_list = np.random.randint(start, end, batch_size) \n",
        "    batch_x.append(np.zeros((batch_size, 3, 100, 100)))\n",
        "    batch_x.append(np.zeros((batch_size, 3, 100, 100)))\n",
        "\n",
        "    for i in range(0, batch_size):\n",
        "        batch_x[0][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
        "        #If train_y has 0 pick from the same class, else pick from any other class\n",
        "        if batch_y[i]==0:\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
        "\n",
        "        else:\n",
        "            temp_list = np.append(temp_cat_list[:class_list[i]].flatten(), temp_cat_list[class_list[i]+1:].flatten())\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_list)]\n",
        "            \n",
        "    return(batch_x, batch_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5gplqrZY7FT"
      },
      "source": [
        "## Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnSmw5aY9n1"
      },
      "source": [
        "#Building a sequential model\n",
        "class CnnNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CnnNetwork, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(3, 64, 10)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 7)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(256 * 4, 4096) # TODO: Change it for sure.\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "# W_init = keras.initializers.RandomNormal(mean = 0.0, stddev = 1e-2)\n",
        "# b_init = keras.initializers.RandomNormal(mean = 0.5, stddev = 1e-2)\n",
        "\n",
        "# model = keras.models.Sequential([\n",
        "#     keras.layers.Conv2D(64, (10,10), activation='relu', input_shape=input_shape, kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
        "#     keras.layers.MaxPooling2D(2, 2),\n",
        "#     keras.layers.Conv2D(128, (7,7), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
        "#     keras.layers.MaxPooling2D(2,2),\n",
        "#     keras.layers.Conv2D(128, (4,4), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
        "#     keras.layers.MaxPooling2D(2,2),\n",
        "#     keras.layers.Conv2D(256, (4,4), activation='relu', kernel_initializer=W_init, bias_initializer=b_init, kernel_regularizer=l2(2e-4)),\n",
        "#     keras.layers.MaxPooling2D(2,2),\n",
        "#     keras.layers.Flatten(),\n",
        "#     keras.layers.Dense(4096, activation='sigmoid', kernel_initializer=W_init, bias_initializer=b_init)\n",
        "# ])\n",
        "\n",
        "########## TODO: \n",
        "# encoded_l = CnnNetwork(left_input)\n",
        "# encoded_r = CnnNetwork(right_input)\n",
        "\n",
        "class SiameseNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.cnn = CnnNetwork()\n",
        "        self.fc1 = nn.Linear(4096, 1)\n",
        "\n",
        "    def forward(self, left, right):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = self.cnn(left)\n",
        "        y = self.cnn(right)\n",
        "        diff = torch.abs(x - y)\n",
        "        z = F.sigmoid(self.fc1(diff))\n",
        "        # z = torch.norm(x-y, dim=1).unsqueeze(1)\n",
        "        return z\n",
        "# TODO: optimizer\n",
        "# learning_rate = 0.0006\n",
        "learning_rate = 0.003\n",
        "siamese_net = SiameseNetwork().cuda()\n",
        "optimizer = torch.optim.Adam(siamese_net.parameters(), lr=learning_rate)\n",
        "\n",
        "# loss = nn.MSELoss()\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "# subtracted = keras.layers.Subtract()([encoded_l, encoded_r])\n",
        "# prediction = Dense(1, activation='sigmoid', bias_initializer=b_init)(subtracted)\n",
        "# siamese_net = Model(input=[left_input, right_input], output=prediction)\n",
        "\n",
        "# optimizer= Adam(learning_rate=0.0006)\n",
        "# siamese_net.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "\n",
        "# plot_model(siamese_net, show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEN8hj5IeDgr"
      },
      "source": [
        "## N-way one-shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb55CMwyeJha"
      },
      "source": [
        "def nway_one_shot(n_way, n_val):\n",
        "    \n",
        "    temp_x = x_val\n",
        "    temp_cat_list = cat_test\n",
        "    batch_x=[]\n",
        "    x_0_choice=[]\n",
        "    n_correct = 0\n",
        "   \n",
        "    class_list = np.random.randint(train_size+1, len(cat_list)-1, n_val)\n",
        "\n",
        "    for i in class_list:  \n",
        "        j = np.random.choice(cat_list[i])\n",
        "        temp=[]\n",
        "        temp.append(np.zeros((n_way, 3, 100, 100)))\n",
        "        temp.append(np.zeros((n_way, 3, 100, 100)))\n",
        "        for k in range(0, n_way):\n",
        "            temp[0][k] = x[j]\n",
        "            \n",
        "            if k==2:\n",
        "                #print(i, k, j, np.random.choice(cat_list[i]))\n",
        "                temp[1][k] = x[np.random.choice(cat_list[i])]\n",
        "            else:\n",
        "                #print(i, k, j, np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten())))\n",
        "                temp[1][k] = x[np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten()))]\n",
        "\n",
        "        # TODO: change here\n",
        "        result = siamese_net(torch.Tensor(temp[0]).cuda(), torch.Tensor(temp[1]).cuda())\n",
        "        result = result.flatten().tolist()\n",
        "        print(\"Results is\", result)\n",
        "        result_index = result.index(min(result))\n",
        "        if result_index == 2:\n",
        "            n_correct = n_correct + 1\n",
        "    print(n_correct, \"correctly classified among\", n_val)\n",
        "    accuracy = (n_correct*100)/n_val\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgVWnfKHe8cs"
      },
      "source": [
        "# batch_x, batch_y = get_batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4JToXLzrsS6"
      },
      "source": [
        "# print(batch_y)\n",
        "# print(len(batch_x))\n",
        "# print(batch_y.shape)\n",
        "# print(batch_x[0][0].shape)\n",
        "# plt.imshow(batch_x[0][10].transpose(1,2, 0))\n",
        "# plt.show()\n",
        "# plt.imshow(batch_x[1][10].transpose(1,2, 0))\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JvNW3l5eW5F"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i-Hf3AjzVjR"
      },
      "source": [
        "# batch_x_0, batch_y_0 = get_batch(batch_size)\n",
        "# batch_x_1, batch_y = get_batch(batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQd2YWrTy_FQ"
      },
      "source": [
        "# siamese_net = SiameseNetwork().cuda()\n",
        "\n",
        "# siamese_outputs = siamese_net(torch.Tensor(batch_x_0[0]).cuda(), torch.Tensor(batch_x_0[1]).cuda())\n",
        "# print(f\"siamese_outputs is {siamese_outputs}\")\n",
        "# print(batch_y_0)\n",
        "# nway_one_shot(n_way, n_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kFcTUnGeYYF"
      },
      "source": [
        "epochs = 30000\n",
        "n_way = 20\n",
        "n_val = 100\n",
        "batch_size = 64\n",
        "\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "for epoch in range(epochs):\n",
        "    if epoch == 0:\n",
        "        accuracy = nway_one_shot(n_way, n_val)\n",
        "\n",
        "    batch_x, batch_y = get_batch(batch_size)\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    siamese_outputs = siamese_net(torch.Tensor(batch_x[0]).cuda(), torch.Tensor(batch_x[1]).cuda())\n",
        "    # print(siamese_net)\n",
        "    # print(f\"siamese_outputs is {siamese_outputs}\")\n",
        "    # for param in siamese_net.parameters():\n",
        "    #     print(param.data)\n",
        "    # print(f\"batch_y is {batch_y}\")\n",
        "    outputs = loss(siamese_outputs, torch.Tensor(batch_y).reshape(64, 1).cuda())\n",
        "    outputs.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch:', epoch, ', Loss:',outputs)\n",
        "    loss_list.append((epoch,outputs.item()))\n",
        "    # print statistics\n",
        "    if epoch % 250 == 0:    # print every 2000 mini-batches\n",
        "        print(\"=============================================\")\n",
        "        accuracy = nway_one_shot(n_way, n_val)\n",
        "        accuracy_list.append((epoch, accuracy))\n",
        "        print('Accuracy as of', epoch, 'epochs:', accuracy)\n",
        "        print(\"=============================================\")\n",
        "        if(accuracy>99):\n",
        "            print(\"Achieved more than 90% Accuracy\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}