{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3u50GTIoxWSaicdAtlrMk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wileyw/DeepLearningDemos/blob/master/SiameseNetwork/siamese_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js4124anRYJO"
      },
      "source": [
        "# Siamese Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwjtWmOdRQeR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icUAqOYASn_k",
        "outputId": "0211a598-79ff-47b7-a5c2-7514a46b0bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/brendenlake/omniglot.git\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'omniglot'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Total 81 (delta 0), reused 0 (delta 0), pack-reused 81\u001b[K\n",
            "Unpacking objects: 100% (81/81), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-HIe5dlT75I",
        "outputId": "0ad33fb9-871c-422d-935b-9af97c9999e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRkoqpVGUV4Q",
        "outputId": "366ab9b8-11fc-4ec6-dd83-ba3f667db0ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!ls /content/drive\n",
        "!mkdir images_background\n",
        "!mkdir strokes_background"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MyDrive  Shareddrives\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmnk-T7PUcPL",
        "outputId": "6940e89c-6068-44fd-87b3-9e7df99886be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python omniglot/python/demo.py"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"omniglot/python/demo.py\", line 114, in <module>\n",
            "    alphabet_names = random.sample(alphabet_names,nalpha) # choose random alphabets\n",
            "  File \"/usr/lib/python3.7/random.py\", line 321, in sample\n",
            "    raise ValueError(\"Sample larger than population or is negative\")\n",
            "ValueError: Sample larger than population or is negative\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-aRHmZaXYkm"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dbmTg1XdUa"
      },
      "source": [
        "base_dir = r'/kaggle/input/fruits/fruits-360/Training/'\n",
        "train_test_split = 0.7\n",
        "no_of_files_in_each_class = 10\n",
        "\n",
        "#Read all the folders in the directory\n",
        "folder_list = os.listdir(base_dir)\n",
        "print( len(folder_list), \"categories found in the dataset\")\n",
        "\n",
        "#Declare training array\n",
        "cat_list = []\n",
        "x = []\n",
        "y = []\n",
        "y_label = 0\n",
        "\n",
        "#Using just no_of_files_in_each_class images per category\n",
        "for folder_name in folder_list:\n",
        "    files_list = os.listdir(os.path.join(base_dir, folder_name))\n",
        "    temp=[]\n",
        "    for file_name in files_list[:no_of_files_in_each_class]:\n",
        "        temp.append(len(x))\n",
        "        x.append(np.asarray(Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB').resize((100, 100))))\n",
        "        y.append(y_label)\n",
        "    y_label+=1\n",
        "    cat_list.append(temp)\n",
        "\n",
        "cat_list = np.asarray(cat_list)\n",
        "x = np.asarray(x)/255.0\n",
        "y = np.asarray(y)\n",
        "print('X, Y shape',x.shape, y.shape, cat_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhS_zspMYXyb"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIRD6DN3YPyA"
      },
      "source": [
        "train_size = int(len(folder_list)*train_test_split)\n",
        "test_size = len(folder_list) - train_size\n",
        "print(train_size, 'classes for training and', test_size, ' classes for testing')\n",
        "\n",
        "train_files = train_size * no_of_files_in_each_class\n",
        "\n",
        "#Training Split\n",
        "x_train = x[:train_files]\n",
        "y_train = y[:train_files]\n",
        "cat_train = cat_list[:train_size]\n",
        "\n",
        "#Validation Split\n",
        "x_val = x[train_files:]\n",
        "y_val = y[train_files:]\n",
        "cat_test = cat_list[train_size:]\n",
        "\n",
        "print('X&Y shape of training data :',x_train.shape, 'and', y_train.shape, cat_train.shape)\n",
        "print('X&Y shape of testing data :' , x_val.shape, 'and', y_val.shape, cat_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuACgkS4YlhM"
      },
      "source": [
        "## Generating Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k-slYI3Yo2D"
      },
      "source": [
        "def get_batch(batch_size=64):\n",
        "    \n",
        "    temp_x = x_train\n",
        "    temp_cat_list = cat_train\n",
        "    start=0\n",
        "    end=train_size\n",
        "    batch_x=[]\n",
        "        \n",
        "    batch_y = np.zeros(batch_size)\n",
        "    batch_y[int(batch_size/2):] = 1\n",
        "    np.random.shuffle(batch_y)\n",
        "    \n",
        "    class_list = np.random.randint(start, end, batch_size) \n",
        "    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n",
        "    batch_x.append(np.zeros((batch_size, 100, 100, 3)))\n",
        "\n",
        "    for i in range(0, batch_size):\n",
        "        batch_x[0][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]  \n",
        "        #If train_y has 0 pick from the same class, else pick from any other class\n",
        "        if batch_y[i]==0:\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
        "\n",
        "        else:\n",
        "            temp_list = np.append(temp_cat_list[:class_list[i]].flatten(), temp_cat_list[class_list[i]+1:].flatten())\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_list)]\n",
        "            \n",
        "    return(batch_x, batch_y)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}