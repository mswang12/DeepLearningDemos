{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handwriting_generator.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNDE2BDNuHzmS78Jvk/R0oB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wileyw/DeepLearningDemos/blob/master/handwriting_generator/handwriting_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RJdrRMEODP1",
        "colab_type": "text"
      },
      "source": [
        "# Handwriting Generator\n",
        "\n",
        "[Reference Jypyter Notebook](https://nbviewer.jupyter.org/github/greydanus/scribe/blob/master/sample.ipynb)\n",
        "\n",
        "[Data](https://github.com/greydanus/scribe/tree/master/data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5FHr3rnZBTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 uninstall tensorflow\n",
        "!pip3 install tensorflow==1.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3xl_Bb3U34l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pgyJGfATJAb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import numpy.matlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "\n",
        "import math\n",
        "import random\n",
        "import time\n",
        "import os\n",
        "import pickle as pickle\n",
        "\n",
        "import tensorflow as tf #built with TensorFlow version 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JokKabHKUl2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDEIBrUYTfAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# in the real project class, we use argparse (https://docs.python.org/3/library/argparse.html)\n",
        "class FakeArgParse():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "args = FakeArgParse()\n",
        "\n",
        "#general model params\n",
        "args.train = False\n",
        "args.rnn_size = 100 #400 hidden units\n",
        "args.tsteps = 256 if args.train else 1\n",
        "args.batch_size = 32 if args.train else 1\n",
        "args.nmixtures = 8 # number of Gaussian mixtures in MDN\n",
        "\n",
        "#window params\n",
        "args.kmixtures = 1 # number of Gaussian mixtures in attention mechanism (for soft convolution window)\n",
        "args.alphabet = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ' #later we'll add an <UNK> slot for unknown chars\n",
        "args.tsteps_per_ascii = 25 # an approximate estimate\n",
        "\n",
        "#book-keeping\n",
        "args.save_path = './saved/model.ckpt'\n",
        "args.data_dir = './data'\n",
        "args.log_dir = './logs/'\n",
        "args.text = 'call me ishmael some years ago'\n",
        "args.style = -1 # don't use a custom style\n",
        "args.bias = 1.0\n",
        "args.eos_prob = 0.4 # threshold probability for ending a stroke"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK1VjQ4KTiNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in real life the model is a class. I used this hack to make the iPython notebook more readable\n",
        "class FakeModel():\n",
        "    def __init__(self):\n",
        "        pass\n",
        "model = FakeModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E0-I_o_Tl6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.char_vec_len = len(args.alphabet) + 1 #plus one for <UNK> token\n",
        "model.ascii_steps = len(args.text)\n",
        "\n",
        "model.graves_initializer = tf.truncated_normal_initializer(mean=0., stddev=.075, seed=None, dtype=tf.float32)\n",
        "model.window_b_initializer = tf.truncated_normal_initializer(mean=-3.0, stddev=.25, seed=None, dtype=tf.float32)\n",
        "\n",
        "# ----- build the basic recurrent network architecture\n",
        "cell_func = tf.contrib.rnn.LSTMCell # could be GRUCell or RNNCell\n",
        "model.cell0 = cell_func(args.rnn_size, state_is_tuple=True, initializer=model.graves_initializer)\n",
        "model.cell1 = cell_func(args.rnn_size, state_is_tuple=True, initializer=model.graves_initializer)\n",
        "model.cell2 = cell_func(args.rnn_size, state_is_tuple=True, initializer=model.graves_initializer)\n",
        "\n",
        "model.input_data = tf.placeholder(dtype=tf.float32, shape=[None, args.tsteps, 3])\n",
        "model.target_data = tf.placeholder(dtype=tf.float32, shape=[None, args.tsteps, 3])\n",
        "model.istate_cell0 = model.cell0.zero_state(batch_size=args.batch_size, dtype=tf.float32)\n",
        "model.istate_cell1 = model.cell1.zero_state(batch_size=args.batch_size, dtype=tf.float32)\n",
        "model.istate_cell2 = model.cell2.zero_state(batch_size=args.batch_size, dtype=tf.float32)\n",
        "\n",
        "#slice the input volume into separate vols for each tstep\n",
        "inputs = [tf.squeeze(input_, [1]) for input_ in tf.split(model.input_data, args.tsteps, 1)]\n",
        "\n",
        "#build model.cell0 computational graph\n",
        "outs_cell0, model.fstate_cell0 = tf.contrib.legacy_seq2seq.rnn_decoder(inputs, model.istate_cell0, \\\n",
        "                                                       model.cell0, loop_function=None, scope='cell0')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPQ6RfcVTopY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----- build the gaussian character window\n",
        "def get_window(alpha, beta, kappa, c):\n",
        "    # phi -> [? x 1 x ascii_steps] and is a tf matrix\n",
        "    # c -> [? x ascii_steps x alphabet] and is a tf matrix\n",
        "    ascii_steps = c.get_shape()[1].value #number of items in sequence\n",
        "    phi = get_phi(ascii_steps, alpha, beta, kappa)\n",
        "    window = tf.matmul(phi,c)\n",
        "    window = tf.squeeze(window, [1]) # window ~ [?,alphabet]\n",
        "    return window, phi\n",
        "\n",
        "#get phi for all t,u (returns a [1 x tsteps] matrix) that defines the window\n",
        "def get_phi(ascii_steps, alpha, beta, kappa):\n",
        "    # alpha, beta, kappa -> [?,kmixtures,1] and each is a tf variable\n",
        "    u = np.linspace(0,ascii_steps-1,ascii_steps) # weight all the U items in the sequence\n",
        "    kappa_term = tf.square( tf.subtract(kappa,u))\n",
        "    exp_term = tf.multiply(-beta,kappa_term)\n",
        "    phi_k = tf.multiply(alpha, tf.exp(exp_term))\n",
        "    phi = tf.reduce_sum(phi_k,1, keep_dims=True)\n",
        "    return phi # phi ~ [?,1,ascii_steps]\n",
        "\n",
        "def get_window_params(i, out_cell0, kmixtures, prev_kappa, reuse=True):\n",
        "    hidden = out_cell0.get_shape()[1]\n",
        "    n_out = 3*kmixtures\n",
        "    with tf.variable_scope('window',reuse=reuse):\n",
        "        window_w = tf.get_variable(\"window_w\", [hidden, n_out], initializer=model.graves_initializer)\n",
        "        window_b = tf.get_variable(\"window_b\", [n_out], initializer=model.window_b_initializer)\n",
        "    abk_hats = tf.nn.xw_plus_b(out_cell0, window_w, window_b) # abk_hats ~ [?,n_out] = \"alpha, beta, kappa hats\"\n",
        "    abk = tf.exp(tf.reshape(abk_hats, [-1, 3*kmixtures,1]))\n",
        "\n",
        "    alpha, beta, kappa = tf.split(abk, 3, 1) # alpha_hat, etc ~ [?,kmixtures]\n",
        "    kappa = kappa + prev_kappa\n",
        "    return alpha, beta, kappa # each ~ [?,kmixtures,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v7qYPOqTq4a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.init_kappa = tf.placeholder(dtype=tf.float32, shape=[None, args.kmixtures, 1]) \n",
        "model.char_seq = tf.placeholder(dtype=tf.float32, shape=[None, model.ascii_steps, model.char_vec_len])\n",
        "wavg_prev_kappa = model.init_kappa\n",
        "prev_window = model.char_seq[:,0,:]\n",
        "\n",
        "#add gaussian window result\n",
        "reuse = False\n",
        "for i in range(len(outs_cell0)):\n",
        "    [alpha, beta, new_kappa] = get_window_params(i, outs_cell0[i], args.kmixtures, wavg_prev_kappa, reuse=reuse)\n",
        "    window, phi = get_window(alpha, beta, new_kappa, model.char_seq)\n",
        "    outs_cell0[i] = tf.concat((outs_cell0[i],window), 1) #concat outputs\n",
        "    outs_cell0[i] = tf.concat((outs_cell0[i],inputs[i]), 1) #concat input data\n",
        "#         prev_kappa = new_kappa #tf.ones_like(new_kappa, dtype=tf.float32, name=\"prev_kappa_ones\") #\n",
        "    wavg_prev_kappa = tf.reduce_mean( new_kappa, reduction_indices=1, keep_dims=True) # mean along kmixtures dimension\n",
        "    reuse = True\n",
        "model.window = window #save the last window (for generation)\n",
        "model.phi = phi #save the last window (for generation)\n",
        "model.new_kappa = new_kappa #save the last window (for generation)\n",
        "model.alpha = alpha #save the last window (for generation)\n",
        "model.wavg_prev_kappa = wavg_prev_kappa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMqKHN-9Ts4i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----- finish building second recurrent cell\n",
        "outs_cell1, model.fstate_cell1 = tf.contrib.legacy_seq2seq.rnn_decoder(outs_cell0, model.istate_cell1, model.cell1, \\\n",
        "                                                    loop_function=None, scope='cell1') #use scope from training\n",
        "\n",
        "# ----- finish building third recurrent cell\n",
        "outs_cell2, model.fstate_cell2 = tf.contrib.legacy_seq2seq.rnn_decoder(outs_cell1, model.istate_cell2, model.cell2, \\\n",
        "                                                    loop_function=None, scope='cell2')\n",
        "\n",
        "out_cell2 = tf.reshape(tf.concat(outs_cell2, 1), [-1, args.rnn_size]) #concat outputs for efficiency"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9GRGGQyTu9Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#put a dense cap on top of the rnn cells (to interface with the mixture density network)\n",
        "n_out = 1 + args.nmixtures * 6 # params = end_of_stroke + 6 parameters per Gaussian\n",
        "with tf.variable_scope('mdn_dense'):\n",
        "    output_w = tf.get_variable(\"output_w\", [args.rnn_size, n_out], initializer=model.graves_initializer)\n",
        "    output_b = tf.get_variable(\"output_b\", [n_out], initializer=model.graves_initializer)\n",
        "\n",
        "output = tf.nn.xw_plus_b(out_cell2, output_w, output_b) #data flows through dense nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETPJ7H1UTwwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ----- build mixture density cap on top of second recurrent cell\n",
        "def gaussian2d(x1, x2, mu1, mu2, s1, s2, rho):\n",
        "    # define gaussian mdn (eq 24, 25 from http://arxiv.org/abs/1308.0850)\n",
        "    x_mu1 = tf.subtract(x1, mu1)\n",
        "    x_mu2 = tf.subtract(x2, mu2)\n",
        "    Z = tf.square(tf.div(x_mu1, s1)) + \\\n",
        "        tf.square(tf.div(x_mu2, s2)) - \\\n",
        "        2*tf.div(tf.multiply(rho, tf.multiply(x_mu1, x_mu2)), tf.multiply(s1, s2))\n",
        "    rho_square_term = 1-tf.square(rho)\n",
        "    power_e = tf.exp(tf.div(-Z,2*rho_square_term))\n",
        "    regularize_term = 2*np.pi*tf.multiply(tf.multiply(s1, s2), tf.sqrt(rho_square_term))\n",
        "    gaussian = tf.div(power_e, regularize_term)\n",
        "    return gaussian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK1-SBrPTycA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now transform dense NN outputs into params for MDN\n",
        "def get_mdn_coef(Z):\n",
        "    # returns the tf slices containing mdn dist params (eq 18...23 of http://arxiv.org/abs/1308.0850)\n",
        "    eos_hat = Z[:, 0:1] #end of sentence tokens\n",
        "    pi_hat, mu1_hat, mu2_hat, sigma1_hat, sigma2_hat, rho_hat = tf.split(Z[:, 1:], 6, 1)\n",
        "    model.pi_hat, model.sigma1_hat, model.sigma2_hat = \\\n",
        "                                        pi_hat, sigma1_hat, sigma2_hat # these are useful for biasing\n",
        "    \n",
        "    eos = tf.sigmoid(-1*eos_hat) # technically we gained a negative sign\n",
        "    pi = tf.nn.softmax(pi_hat) # softmax z_pi:\n",
        "    mu1 = mu1_hat; mu2 = mu2_hat # leave mu1, mu2 as they are\n",
        "    sigma1 = tf.exp(sigma1_hat); sigma2 = tf.exp(sigma2_hat) # exp for sigmas\n",
        "    rho = tf.tanh(rho_hat) # tanh for rho (squish between -1 and 1)\n",
        "\n",
        "    return [eos, pi, mu1, mu2, sigma1, sigma2, rho]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk92hDYkT0Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape target data (as we did the input data)\n",
        "flat_target_data = tf.reshape(model.target_data,[-1, 3])\n",
        "[x1_data, x2_data, eos_data] = tf.split(flat_target_data, 3, 1) #we might as well split these now\n",
        "[model.eos, model.pi, model.mu1, model.mu2, model.sigma1, model.sigma2, model.rho] = get_mdn_coef(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqN5G9I4VY4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/greydanus/scribe.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-meqVeQHVcP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls scribe/data\n",
        "!cp -r scribe/data data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byGHNLDLWzk9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/wileyw/DeepLearningDemos.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pETW92lyW2B_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls DeepLearningDemos/handwriting_generator/saved.tgz\n",
        "!tar -xzvf DeepLearningDemos/handwriting_generator/saved.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aswhBIJYXCeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls saved"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svBC8TjsT2DC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.sess = tf.InteractiveSession()\n",
        "model.saver = tf.train.Saver(tf.global_variables())\n",
        "model.sess.run(tf.global_variables_initializer())\n",
        "\n",
        "load_was_success = True # yes, I'm being optimistic\n",
        "global_step = 0\n",
        "try:\n",
        "    save_dir = '/'.join(args.save_path.split('/')[:-1])\n",
        "    ckpt = tf.train.get_checkpoint_state(save_dir)\n",
        "    load_path = ckpt.model_checkpoint_path\n",
        "    print('------------')\n",
        "    print(load_path)\n",
        "    model.saver.restore(model.sess, load_path)\n",
        "    print('----------')\n",
        "except Exception as e:\n",
        "    print(\"no saved model to load. starting new session\")\n",
        "    print(e)\n",
        "    load_was_success = False\n",
        "else:\n",
        "    print(\"loaded model: {}\".format(load_path))\n",
        "    model.saver = tf.train.Saver(tf.global_variables())\n",
        "    global_step = int(load_path.split('-')[-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY1MvW7UT3vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# utility function for converting input ascii characters into vectors the network can understand.\n",
        "# index position 0 means \"unknown\"\n",
        "def to_one_hot(s, ascii_steps, alphabet):\n",
        "    steplimit=3e3; s = s[:3e3] if len(s) > 3e3 else s # clip super-long strings\n",
        "    seq = [alphabet.find(char) + 1 for char in s]\n",
        "    if len(seq) >= ascii_steps:\n",
        "        seq = seq[:ascii_steps]\n",
        "    else:\n",
        "        seq = seq + [0]*(ascii_steps - len(seq))\n",
        "    one_hot = np.zeros((ascii_steps,len(alphabet)+1))\n",
        "    one_hot[np.arange(ascii_steps),seq] = 1\n",
        "    return one_hot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swyEhEvpT6C0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_style_states(model, args):\n",
        "    with open(os.path.join(args.data_dir, 'styles.p'),'r') as f:\n",
        "        style_strokes, style_strings = pickle.load(f)\n",
        "\n",
        "    style_strokes, style_string = style_strokes[args.style], style_strings[args.style]\n",
        "    style_onehot = [to_one_hot(style_string, model.ascii_steps, args.alphabet)]\n",
        "\n",
        "    c0, c1, c2 = model.istate_cell0.c.eval(), model.istate_cell1.c.eval(), model.istate_cell2.c.eval()\n",
        "    h0, h1, h2 = model.istate_cell0.h.eval(), model.istate_cell1.h.eval(), model.istate_cell2.h.eval()\n",
        "    if args.style is -1: return [c0, c1, c2, h0, h1, h2] #model 'chooses' random style\n",
        "        \n",
        "    style_stroke = np.zeros((1, 1, 3), dtype=np.float32)\n",
        "    style_kappa = np.zeros((1, args.kmixtures, 1))\n",
        "    prime_len = 500 # must be <= 700\n",
        "    \n",
        "    for i in xrange(prime_len):\n",
        "        style_stroke[0][0] = style_strokes[i,:]\n",
        "        feed = {model.input_data: style_stroke, model.char_seq: style_onehot, model.init_kappa: style_kappa, \\\n",
        "                model.istate_cell0.c: c0, model.istate_cell1.c: c1, model.istate_cell2.c: c2, \\\n",
        "                model.istate_cell0.h: h0, model.istate_cell1.h: h1, model.istate_cell2.h: h2}\n",
        "        fetch = [model.wavg_prev_kappa, \\\n",
        "                 model.fstate_cell0.c, model.fstate_cell1.c, model.fstate_cell2.c,\n",
        "                 model.fstate_cell0.h, model.fstate_cell1.h, model.fstate_cell2.h]\n",
        "        [style_kappa, c0, c1, c2, h0, h1, h2] = model.sess.run(fetch, feed)\n",
        "    return [c0, c1, c2, np.zeros_like(h0), np.zeros_like(h1), np.zeros_like(h2)] #only the c vectors should be primed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZT-9wdXXX4z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls data\n",
        "print(args.data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmPeBpdTT8XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize some sampling parameters\n",
        "one_hot = [to_one_hot(args.text, model.ascii_steps, args.alphabet)]  # convert input string to one-hot vector\n",
        "print(args)\n",
        "[c0, c1, c2, h0, h1, h2] = get_style_states(model, args)              # get numpy zeros states for all three LSTMs\n",
        "kappa = np.zeros((1, args.kmixtures, 1))                              # attention's read head starts at index 0\n",
        "prev_x = np.asarray([[[0, 0, 1]]], dtype=np.float32)                  # start with a pen stroke at (0,0)\n",
        "\n",
        "strokes, pis, windows, phis, kappas = [], [], [], [], []              # the data we're going to generate will go here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp53kJkFT-Ii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample_gaussian2d(mu1, mu2, s1, s2, rho):\n",
        "    mean = [mu1, mu2]\n",
        "    cov = [[s1*s1, rho*s1*s2], [rho*s1*s2, s2*s2]]\n",
        "    x = np.random.multivariate_normal(mean, cov, 1)\n",
        "    return x[0][0], x[0][1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8qxTGZtUCq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "finished = False ; i = 0\n",
        "while not finished and i < 800:\n",
        "    feed = {model.input_data: prev_x, model.char_seq: one_hot, model.init_kappa: kappa, \\\n",
        "            model.istate_cell0.c: c0, model.istate_cell1.c: c1, model.istate_cell2.c: c2, \\\n",
        "            model.istate_cell0.h: h0, model.istate_cell1.h: h1, model.istate_cell2.h: h2}\n",
        "    fetch = [model.pi_hat, model.mu1, model.mu2, model.sigma1_hat, model.sigma2_hat, model.rho, model.eos, \\\n",
        "             model.window, model.phi, model.new_kappa, model.wavg_prev_kappa, model.alpha, \\\n",
        "             model.fstate_cell0.c, model.fstate_cell1.c, model.fstate_cell2.c,\\\n",
        "             model.fstate_cell0.h, model.fstate_cell1.h, model.fstate_cell2.h]\n",
        "    [pi_hat, mu1, mu2, sigma1_hat, sigma2_hat, rho, eos, window, phi, kappa, wavg_kappa, alpha, \\\n",
        "             c0, c1, c2, h0, h1, h2] = model.sess.run(fetch, feed)\n",
        "    \n",
        "    #bias stuff:\n",
        "    sigma1 = np.exp(sigma1_hat - args.bias)\n",
        "    sigma2 = np.exp(sigma2_hat - args.bias)\n",
        "    pi_hat *= 1 + args.bias # apply bias\n",
        "    pi = np.zeros_like(pi_hat) # need to preallocate\n",
        "    pi[0] = np.exp(pi_hat[0]) / np.sum(np.exp(pi_hat[0]), axis=0) # softmax\n",
        "    \n",
        "    # choose a component from the MDN\n",
        "    idx = np.random.choice(pi.shape[1], p=pi[0])\n",
        "    eos = 1 if args.eos_prob < eos[0][0] else 0 # use 0.5 as arbitrary boundary\n",
        "    x1, x2 = sample_gaussian2d(mu1[0][idx], mu2[0][idx], sigma1[0][idx], sigma2[0][idx], rho[0][idx])\n",
        "        \n",
        "    # store the info at this time step\n",
        "    windows.append(window)\n",
        "    phis.append(phi[0])\n",
        "    kappas.append(kappa[0])\n",
        "    pis.append(pi[0])\n",
        "    strokes.append([mu1[0][idx], mu2[0][idx], sigma1[0][idx], sigma2[0][idx], rho[0][idx], eos])\n",
        "    \n",
        "    # test if finished (has the read head seen the whole ascii sequence?)\n",
        "    main_kappa_idx = np.where(alpha[0]==np.max(alpha[0])); # choose the read head with the highes alpha value\n",
        "    finished = True if kappa[0][main_kappa_idx] > len(args.text) + 1 else False\n",
        "    \n",
        "    # new input is previous output\n",
        "    prev_x[0][0] = np.array([x1, x2, eos], dtype=np.float32)\n",
        "    kappa = wavg_kappa\n",
        "    i+=1\n",
        "windows = np.vstack(windows)\n",
        "phis = np.vstack(phis)\n",
        "kappas = np.vstack(kappas)\n",
        "pis = np.vstack(pis)\n",
        "strokes = np.vstack(strokes)\n",
        "\n",
        "# the network predicts the displacements between pen points, so do a running sum over the time dimension\n",
        "strokes[:,:2] = np.cumsum(strokes[:,:2], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqXN61oUUE4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plots parameters from the attention mechanism\n",
        "def window_plots(phis, windows):\n",
        "    plt.figure(figsize=(16,4))\n",
        "    plt.subplot(121)\n",
        "    plt.title('Phis', fontsize=20)\n",
        "    plt.xlabel(\"ascii #\", fontsize=15)\n",
        "    plt.ylabel(\"time steps\", fontsize=15)\n",
        "    plt.imshow(phis, interpolation='nearest', aspect='auto', cmap=cm.jet)\n",
        "    plt.subplot(122)\n",
        "    plt.title('Soft attention window', fontsize=20)\n",
        "    plt.xlabel(\"one-hot vector\", fontsize=15)\n",
        "    plt.ylabel(\"time steps\", fontsize=15)\n",
        "    plt.imshow(windows, interpolation='nearest', aspect='auto', cmap=cm.jet)\n",
        "    \n",
        "window_plots(phis, windows)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oaw7VtGnUG_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,4))\n",
        "plt.title(\"How MDN $\\pi$ values change over time\", fontsize=15)\n",
        "plt.xlabel(\"$\\pi$ values\", fontsize=15)\n",
        "plt.ylabel(\"time step\", fontsize=15)\n",
        "plt.imshow(pis, interpolation='nearest', aspect='auto', cmap=cm.jet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hC4RohGfUJVG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gauss_plot(strokes, title, figsize = (20,2)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    import matplotlib.mlab as mlab\n",
        "    buff = 1 ; epsilon = 1e-4\n",
        "    minx, maxx = np.min(strokes[:,0])-buff, np.max(strokes[:,0])+buff\n",
        "    miny, maxy = np.min(strokes[:,1])-buff, np.max(strokes[:,1])+buff\n",
        "    delta = abs(maxx-minx)/400. ;\n",
        "\n",
        "    x = np.arange(minx, maxx, delta)\n",
        "    y = np.arange(miny, maxy, delta)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    Z = np.zeros_like(X)\n",
        "    for i in range(strokes.shape[0]):\n",
        "        gauss = mlab.bivariate_normal(X, Y, mux=strokes[i,0], muy=strokes[i,1], \\\n",
        "            sigmax=strokes[i,2], sigmay=strokes[i,3], sigmaxy=0) # sigmaxy=strokes[i,4] gives error\n",
        "        Z += gauss * np.power(strokes[i,3] + strokes[i,2], .4) / (np.max(gauss) + epsilon)\n",
        "\n",
        "    plt.title(title, fontsize=20)\n",
        "    plt.imshow(Z)\n",
        "    \n",
        "gauss_plot(strokes, \"Stroke probability\", figsize = (2*model.ascii_steps,4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmsxtSVbULW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plots the stroke data (handwriting!)\n",
        "def line_plot(strokes, title, figsize = (20,2)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    eos_preds = np.where(strokes[:,-1] == 1)\n",
        "    eos_preds = [0] + list(eos_preds[0]) + [-1] #add start and end indices\n",
        "    for i in range(len(eos_preds)-1):\n",
        "        start = eos_preds[i]+1\n",
        "        stop = eos_preds[i+1]\n",
        "        plt.plot(strokes[start:stop,0], strokes[start:stop,1],'b-', linewidth=2.0) #draw a stroke\n",
        "    plt.title(title,  fontsize=20)\n",
        "    plt.gca().invert_yaxis()\n",
        "    plt.show()\n",
        "    \n",
        "line_plot(strokes, 'Line plot: \"{}\"'.format(args.text), figsize=(model.ascii_steps,2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HUGzFrhOKFx",
        "colab_type": "text"
      },
      "source": [
        "# Resources\n",
        "- https://github.com/topics/handwriting-synthesis\n",
        "- https://github.com/sjvasquez/handwriting-synthesis\n",
        "- http://www.fki.inf.unibe.ch/databases/iam-on-line-handwriting-database"
      ]
    }
  ]
}