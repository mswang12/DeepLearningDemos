{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "siamese_network.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/wileyw/DeepLearningDemos/blob/master/SiameseNetwork/siamese_network.ipynb",
      "authorship_tag": "ABX9TyOZHjoOx1otGqcINsX1Ct+u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wileyw/DeepLearningDemos/blob/master/TwinNetwork/twin_network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "js4124anRYJO"
      },
      "source": [
        "# Twin Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwjtWmOdRQeR"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icUAqOYASn_k"
      },
      "source": [
        "# !unzip drive/MyDrive/fruits-360.zip -d drive/MyDrive\n",
        "# https://towardsdatascience.com/siamese-networks-line-by-line-explanation-for-beginners-55b8be1d2fc6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-aRHmZaXYkm"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_dbmTg1XdUa"
      },
      "source": [
        "base_dir = r'/content/drive/MyDrive/fruits-360/Training/'\n",
        "train_test_split = 0.7\n",
        "no_of_files_in_each_class = 10\n",
        "\n",
        "#Read all the folders in the directory\n",
        "folder_list = os.listdir(base_dir)\n",
        "print( len(folder_list), \"categories found in the dataset\")\n",
        "\n",
        "#Declare training array\n",
        "cat_list = []\n",
        "x = []\n",
        "y = []\n",
        "y_label = 0\n",
        "\n",
        "#Using just no_of_files_in_each_class images per category\n",
        "for folder_name in folder_list:\n",
        "    files_list = os.listdir(os.path.join(base_dir, folder_name))\n",
        "    if len(files_list) < no_of_files_in_each_class:\n",
        "      print(f\"skipping {folder_name}\")\n",
        "      continue\n",
        "    temp=[]\n",
        "    for file_name in files_list[:no_of_files_in_each_class]:\n",
        "        temp.append(len(x))\n",
        "        x.append(np.asarray(Image.open(os.path.join(base_dir, folder_name, file_name)).convert('RGB').resize((100, 100))))\n",
        "        y.append(y_label)\n",
        "    y_label+=1\n",
        "    cat_list.append(temp)\n",
        "\n",
        "cat_list = np.asarray(cat_list)\n",
        "x = np.asarray(x)/255.0\n",
        "y = np.asarray(y)\n",
        "print('X, Y shape',x.shape, y.shape, cat_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfdur2NiUyD"
      },
      "source": [
        "# Adapt x input dimension to PyTorch format.\n",
        "x = x.transpose(0, 3, 1, 2)\n",
        "print('X, Y shape',x.shape, y.shape, cat_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhS_zspMYXyb"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIRD6DN3YPyA"
      },
      "source": [
        "train_size = int(len(folder_list)*train_test_split)\n",
        "test_size = len(folder_list) - train_size\n",
        "print(train_size, 'classes for training and', test_size, ' classes for testing')\n",
        "\n",
        "train_files = train_size * no_of_files_in_each_class\n",
        "\n",
        "#Training Split\n",
        "x_train = x[:train_files]\n",
        "y_train = y[:train_files]\n",
        "cat_train = cat_list[:train_size]\n",
        "\n",
        "#Validation Split\n",
        "x_val = x[train_files:]\n",
        "y_val = y[train_files:]\n",
        "cat_test = cat_list[train_size:]\n",
        "\n",
        "print('X&Y shape of training data :',x_train.shape, 'and', y_train.shape, cat_train.shape)\n",
        "print('X&Y shape of testing data :' , x_val.shape, 'and', y_val.shape, cat_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuACgkS4YlhM"
      },
      "source": [
        "## Generating Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k-slYI3Yo2D"
      },
      "source": [
        "def get_batch(batch_size=64):\n",
        "    \n",
        "    temp_x = x_train\n",
        "    temp_cat_list = cat_train\n",
        "    start=0\n",
        "    end=train_size\n",
        "    batch_x=[]\n",
        "        \n",
        "    batch_y = np.zeros(batch_size)\n",
        "    batch_y[int(batch_size/2):] = 1\n",
        "    np.random.shuffle(batch_y)\n",
        "    \n",
        "    class_list = np.random.randint(start, end, batch_size) \n",
        "    batch_x.append(np.zeros((batch_size, 3, 100, 100)))\n",
        "    batch_x.append(np.zeros((batch_size, 3, 100, 100)))\n",
        "\n",
        "    for i in range(0, batch_size):\n",
        "        batch_x[0][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
        "        #If train_y has 0 pick from the same class, else pick from any other class\n",
        "        if batch_y[i]==0:\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_cat_list[class_list[i]])]\n",
        "\n",
        "        else:\n",
        "            temp_list = np.append(temp_cat_list[:class_list[i]].flatten(), temp_cat_list[class_list[i]+1:].flatten())\n",
        "            batch_x[1][i] = temp_x[np.random.choice(temp_list)]\n",
        "            \n",
        "    return(batch_x, batch_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5gplqrZY7FT"
      },
      "source": [
        "## Twin Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcnSmw5aY9n1"
      },
      "source": [
        "#Building a sequential model\n",
        "class CnnNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CnnNetwork, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(3, 64, 10)\n",
        "        self.conv2 = nn.Conv2d(64, 128, 7)\n",
        "        self.conv3 = nn.Conv2d(128, 128, 4)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(256 * 4, 4096)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv4(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.sigmoid(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "class TwinNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TwinNetwork, self).__init__()\n",
        "        self.cnn = CnnNetwork()\n",
        "        self.fc1 = nn.Linear(4096, 1)\n",
        "\n",
        "    def forward(self, left, right):\n",
        "        x = self.cnn(left)\n",
        "        y = self.cnn(right)\n",
        "        diff = torch.abs(x - y)\n",
        "        z = F.sigmoid(self.fc1(diff))\n",
        "        return z\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEN8hj5IeDgr"
      },
      "source": [
        "## N-way one-shot Learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb55CMwyeJha"
      },
      "source": [
        "def nway_one_shot(n_way, n_val):\n",
        "    \n",
        "    temp_x = x_val\n",
        "    temp_cat_list = cat_test\n",
        "    batch_x=[]\n",
        "    x_0_choice=[]\n",
        "    n_correct = 0\n",
        "   \n",
        "    class_list = np.random.randint(train_size+1, len(cat_list)-1, n_val)\n",
        "\n",
        "    for i in class_list:  \n",
        "        j = np.random.choice(cat_list[i])\n",
        "        temp=[]\n",
        "        temp.append(np.zeros((n_way, 3, 100, 100)))\n",
        "        temp.append(np.zeros((n_way, 3, 100, 100)))\n",
        "        for k in range(0, n_way):\n",
        "            temp[0][k] = x[j]\n",
        "            # 2 is arbitrary here, as 0 is the default number when all numbers\n",
        "            # are equal, which leads to wrong conclusions.\n",
        "            if k==2:\n",
        "                temp[1][k] = x[np.random.choice(cat_list[i])]\n",
        "            else:\n",
        "                temp[1][k] = x[np.random.choice(np.append(cat_list[:i].flatten(), cat_list[i+1:].flatten()))]\n",
        "\n",
        "        result = twin_net(torch.Tensor(temp[0]).cuda(), torch.Tensor(temp[1]).cuda())\n",
        "        result = result.flatten().tolist()\n",
        "        result_index = result.index(min(result))\n",
        "        if result_index == 2:\n",
        "            n_correct = n_correct + 1\n",
        "    print(n_correct, \"correctly classified among\", n_val)\n",
        "    accuracy = (n_correct*100)/n_val\n",
        "    return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHZfladnDF1"
      },
      "source": [
        "# Tools to display batch data graphically\n",
        "def display_batch(batch_x, batch_y, batch_size=64):\n",
        "  num = int(batch_size ** 0.5)\n",
        "  combined_left = np.zeros((num*100, num*100, 3))\n",
        "  combined_right = np.zeros((num*100, num*100, 3))\n",
        "  count = 0\n",
        "  for i in range(num):\n",
        "    for j in range(num):\n",
        "      left_image = batch_x[0][count].transpose(1, 2, 0)\n",
        "      right_image = batch_x[1][count].transpose(1, 2, 0)\n",
        "      combined_left[i*100:(i+1)*100, j*100:(j+1)*100, :] = left_image\n",
        "      combined_right[i*100:(i+1)*100, j*100:(j+1)*100, :] = right_image\n",
        "      count += 1\n",
        "  plt.imshow(combined_left)\n",
        "  plt.show()\n",
        "  plt.imshow(combined_right)\n",
        "  plt.show()\n",
        "  print(\"batch_y is\")\n",
        "  print(np.reshape(batch_y, (-1, num)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JvNW3l5eW5F"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kFcTUnGeYYF"
      },
      "source": [
        "# We started learning_rate at 0.0006, but it was too coarse.\n",
        "learning_rate = 0.0001\n",
        "twin_net = TwinNetwork().cuda()\n",
        "optimizer = torch.optim.Adam(twin_net.parameters(), lr=learning_rate)\n",
        "\n",
        "loss = nn.BCELoss()\n",
        "\n",
        "epochs = 30000\n",
        "n_way = 20\n",
        "n_val = 100\n",
        "batch_size = 64\n",
        "\n",
        "loss_list=[]\n",
        "accuracy_list=[]\n",
        "for epoch in range(epochs):\n",
        "    if epoch == 0:\n",
        "        accuracy = nway_one_shot(n_way, n_val)\n",
        "        print('Accuracy as of', epoch, 'epochs:', accuracy)\n",
        "    batch_x, batch_y = get_batch(batch_size)\n",
        "    # display_batch(batch_x, batch_y)\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward + backward + optimize\n",
        "    twin_outputs = twin_net(torch.Tensor(batch_x[0]).cuda(), torch.Tensor(batch_x[1]).cuda())\n",
        "    outputs = loss(twin_outputs, torch.Tensor(batch_y).reshape(64, 1).cuda())\n",
        "    outputs.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # print('Epoch:', epoch, ', Loss:',outputs)\n",
        "    loss_list.append(outputs.item())\n",
        "    # print statistics\n",
        "    if epoch % 250 == 0:\n",
        "        print(\"=============================================\")\n",
        "        accuracy = nway_one_shot(n_way, n_val)\n",
        "        accuracy_list.append((epoch, accuracy))\n",
        "        print('Accuracy as of', epoch, 'epochs:', accuracy)\n",
        "        print('Epoch:', epoch, ', Loss:',np.mean(loss_list[-250:]))\n",
        "        print(\"=============================================\")\n",
        "        if(accuracy>90):\n",
        "            print(\"Achieved more than 90% Accuracy\")\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}