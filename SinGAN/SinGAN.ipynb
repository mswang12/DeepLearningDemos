{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SinGAN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOKNR8Y0Tbl4Yrh1WgbsWL7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wileyw/DeepLearningDemos/blob/master/SinGAN/SinGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_teh4A4skGRT",
        "colab_type": "text"
      },
      "source": [
        "# SinGAN\n",
        "\n",
        "[Official SinGAN Repository](https://github.com/tamarott/SinGAN)\n",
        "\n",
        "In this notebook, we will implement and create a SinGAN homework assignment for other's to learn how to implement SinGAN as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF-QL9B0z7sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/mswang12/SinGAN.git\n",
        "%cd /content/SinGAN/\n",
        "!git checkout experimental\n",
        "# Explore Input images here:\n",
        "%cd /content/SinGAN/Input/Images/\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTHAHNbnL5W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print('original image')\n",
        "original_img_path = '/content/SinGAN/Input/Images/trees3.png'\n",
        "img = cv2.imread(original_img_path)\n",
        "cv2_imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nUJqiIxbzs6",
        "colab_type": "text"
      },
      "source": [
        "# Let's train SinGAN here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tpJ52gVK_DGj",
        "colab_type": "text"
      },
      "source": [
        "## Notes\n",
        "1. mode: \"rand\" vs \"rec\" - rand generates noise on the fly, it uses Z_opt only for size. rec uses recorded Z_opt without changed it\n",
        "2. z_opt is unique noise, it's for monitoring the training results with fixed noise\n",
        "3. Things to figure out, sample around the images for cropping\n",
        "4. draw_concat() creates a new image with the inputs (noise + previous image, previous image)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8KF6KxWcFpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's pull out the important functions we want to reimplement\n",
        "def train_single_scale2(netD,netG,reals,Gs,Zs,in_s,NoiseAmp,opt,centers=None):\n",
        "    print('placeholder')\n",
        "    real = reals[len(Gs)]\n",
        "    opt.nzx = real.shape[2]#+(opt.ker_size-1)*(opt.num_layer)\n",
        "    opt.nzy = real.shape[3]#+(opt.ker_size-1)*(opt.num_layer)\n",
        "    opt.receptive_field = opt.ker_size + ((opt.ker_size-1)*(opt.num_layer-1))*opt.stride\n",
        "    pad_noise = int(((opt.ker_size - 1) * opt.num_layer) / 2)\n",
        "    pad_image = int(((opt.ker_size - 1) * opt.num_layer) / 2)\n",
        "    if opt.mode == 'animation_train':\n",
        "        opt.nzx = real.shape[2]+(opt.ker_size-1)*(opt.num_layer)\n",
        "        opt.nzy = real.shape[3]+(opt.ker_size-1)*(opt.num_layer)\n",
        "        pad_noise = 0\n",
        "    m_noise = nn.ZeroPad2d(int(pad_noise))\n",
        "    m_image = nn.ZeroPad2d(int(pad_image))\n",
        "\n",
        "    alpha = opt.alpha\n",
        "\n",
        "    fixed_noise = functions.generate_noise([opt.nc_z,opt.nzx,opt.nzy],device=opt.device)\n",
        "    z_opt = torch.full(fixed_noise.shape, 0, device=opt.device)\n",
        "    z_opt = m_noise(z_opt)\n",
        "\n",
        "    # setup optimizer\n",
        "    optimizerD = optim.Adam(netD.parameters(), lr=opt.lr_d, betas=(opt.beta1, 0.999))\n",
        "    optimizerG = optim.Adam(netG.parameters(), lr=opt.lr_g, betas=(opt.beta1, 0.999))\n",
        "    schedulerD = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerD,milestones=[1600],gamma=opt.gamma)\n",
        "    schedulerG = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizerG,milestones=[1600],gamma=opt.gamma)\n",
        "\n",
        "    errD2plot = []\n",
        "    errG2plot = []\n",
        "    D_real2plot = []\n",
        "    D_fake2plot = []\n",
        "    z_opt2plot = []\n",
        "\n",
        "\n",
        "    # NOTE: Train for only 100 epochs to speed things up\n",
        "    #for epoch in range(int(opt.niter / 2)):\n",
        "    for epoch in range(100):\n",
        "        if (Gs == []) & (opt.mode != 'SR_train'):\n",
        "            z_opt = functions.generate_noise([1,opt.nzx,opt.nzy], device=opt.device)\n",
        "            z_opt = m_noise(z_opt.expand(1,3,opt.nzx,opt.nzy))\n",
        "            noise_ = functions.generate_noise([1,opt.nzx,opt.nzy], device=opt.device)\n",
        "            noise_ = m_noise(noise_.expand(1,3,opt.nzx,opt.nzy))\n",
        "        else:\n",
        "            noise_ = functions.generate_noise([opt.nc_z,opt.nzx,opt.nzy], device=opt.device)\n",
        "            noise_ = m_noise(noise_)\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize D(x) + D(G(z))\n",
        "        ###########################\n",
        "        for j in range(int(opt.Dsteps)):\n",
        "            # train with real\n",
        "            netD.zero_grad()\n",
        "\n",
        "            output = netD(real).to(opt.device)\n",
        "            #D_real_map = output.detach()\n",
        "            errD_real = -output.mean()#-a\n",
        "            errD_real.backward(retain_graph=True)\n",
        "            D_x = -errD_real.item()\n",
        "\n",
        "            # train with fake\n",
        "            if (j==0) & (epoch == 0):\n",
        "                if (Gs == []) & (opt.mode != 'SR_train'):\n",
        "                    prev = torch.full([1,opt.nc_z,opt.nzx,opt.nzy], 0, device=opt.device)\n",
        "                    in_s = prev\n",
        "                    prev = m_image(prev)\n",
        "                    z_prev = torch.full([1,opt.nc_z,opt.nzx,opt.nzy], 0, device=opt.device)\n",
        "                    z_prev = m_noise(z_prev)\n",
        "                    opt.noise_amp = 1\n",
        "                elif opt.mode == 'SR_train':\n",
        "                    z_prev = in_s\n",
        "                    criterion = nn.MSELoss()\n",
        "                    RMSE = torch.sqrt(criterion(real, z_prev))\n",
        "                    opt.noise_amp = opt.noise_amp_init * RMSE\n",
        "                    z_prev = m_image(z_prev)\n",
        "                    prev = z_prev\n",
        "                else:\n",
        "                    prev = draw_concat(Gs,Zs,reals,NoiseAmp,in_s,'rand',m_noise,m_image,opt)\n",
        "                    prev = m_image(prev)\n",
        "                    z_prev = draw_concat(Gs,Zs,reals,NoiseAmp,in_s,'rec',m_noise,m_image,opt)\n",
        "                    criterion = nn.MSELoss()\n",
        "                    RMSE = torch.sqrt(criterion(real, z_prev))\n",
        "                    opt.noise_amp = opt.noise_amp_init*RMSE\n",
        "                    z_prev = m_image(z_prev)\n",
        "            else:\n",
        "                prev = draw_concat(Gs,Zs,reals,NoiseAmp,in_s,'rand',m_noise,m_image,opt)\n",
        "                prev = m_image(prev)\n",
        "\n",
        "            if opt.mode == 'paint_train':\n",
        "                prev = functions.quant2centers(prev,centers)\n",
        "                plt.imsave('%s/prev.png' % (opt.outf), functions.convert_image_np(prev), vmin=0, vmax=1)\n",
        "\n",
        "            if (Gs == []) & (opt.mode != 'SR_train'):\n",
        "                noise = noise_\n",
        "            else:\n",
        "                noise = opt.noise_amp*noise_+prev\n",
        "\n",
        "            fake = netG(noise.detach(),prev)\n",
        "            output = netD(fake.detach())\n",
        "            # NOTE: netD outputs a tensor. The Discriminator is fully convolution and does not depend on the size of the image.\n",
        "            # An image is real or fake depending on the mean of the output tensor.\n",
        "            # Maybe we can talk about this in our Blog post?\n",
        "            errD_fake = output.mean()\n",
        "            errD_fake.backward(retain_graph=True)\n",
        "            D_G_z = output.mean().item()\n",
        "\n",
        "            gradient_penalty = functions.calc_gradient_penalty(netD, real, fake, opt.lambda_grad, opt.device)\n",
        "            gradient_penalty.backward()\n",
        "\n",
        "            errD = errD_real + errD_fake + gradient_penalty\n",
        "            optimizerD.step()\n",
        "\n",
        "        errD2plot.append(errD.detach())\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize D(G(z))\n",
        "        ###########################\n",
        "\n",
        "        for j in range(opt.Gsteps):\n",
        "            netG.zero_grad()\n",
        "            output = netD(fake)\n",
        "            #D_fake_map = output.detach()\n",
        "            errG = -output.mean()\n",
        "            errG.backward(retain_graph=True)\n",
        "            if alpha!=0:\n",
        "                loss = nn.MSELoss()\n",
        "                if opt.mode == 'paint_train':\n",
        "                    z_prev = functions.quant2centers(z_prev, centers)\n",
        "                    plt.imsave('%s/z_prev.png' % (opt.outf), functions.convert_image_np(z_prev), vmin=0, vmax=1)\n",
        "                Z_opt = opt.noise_amp*z_opt+z_prev\n",
        "                rec_loss = alpha*loss(netG(Z_opt.detach(),z_prev),real)\n",
        "                rec_loss.backward(retain_graph=True)\n",
        "                rec_loss = rec_loss.detach()\n",
        "            else:\n",
        "                Z_opt = z_opt\n",
        "                rec_loss = 0\n",
        "\n",
        "            optimizerG.step()\n",
        "\n",
        "        errG2plot.append(errG.detach()+rec_loss)\n",
        "        D_real2plot.append(D_x)\n",
        "        D_fake2plot.append(D_G_z)\n",
        "        z_opt2plot.append(rec_loss)\n",
        "\n",
        "        if epoch % 25 == 0 or epoch == (opt.niter-1):\n",
        "            print('scale %d:[%d/%d]' % (len(Gs), epoch, opt.niter))\n",
        "\n",
        "        if epoch % 500 == 0 or epoch == (opt.niter-1):\n",
        "            plt.imsave('%s/fake_sample.png' %  (opt.outf), functions.convert_image_np(fake.detach()), vmin=0, vmax=1)\n",
        "            plt.imsave('%s/G(z_opt).png'    % (opt.outf),  functions.convert_image_np(netG(Z_opt.detach(), z_prev).detach()), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/D_fake.png'   % (opt.outf), functions.convert_image_np(D_fake_map))\n",
        "            #plt.imsave('%s/D_real.png'   % (opt.outf), functions.convert_image_np(D_real_map))\n",
        "            #plt.imsave('%s/z_opt.png'    % (opt.outf), functions.convert_image_np(z_opt.detach()), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/prev.png'     %  (opt.outf), functions.convert_image_np(prev), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/noise.png'    %  (opt.outf), functions.convert_image_np(noise), vmin=0, vmax=1)\n",
        "            #plt.imsave('%s/z_prev.png'   % (opt.outf), functions.convert_image_np(z_prev), vmin=0, vmax=1)\n",
        "\n",
        "\n",
        "            torch.save(z_opt, '%s/z_opt.pth' % (opt.outf))\n",
        "\n",
        "        schedulerD.step()\n",
        "        schedulerG.step()\n",
        "\n",
        "    functions.save_networks(netG,netD,z_opt,opt)\n",
        "    return z_opt,in_s,netG    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RjmZVv6v6w_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the Networks here\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvBlock(nn.Sequential):\n",
        "  def __init__(self, in_channel, out_channel, ker_size, padd, stride):\n",
        "    super(ConvBlock, self).__init__()\n",
        "    # NOTE: Is there a reason why BatchNorm2d is before and not after LeakReLU?\n",
        "    self.add_module('conv', nn.Conv2d(in_channel, out_channel, kernel_size=ker_size, stride=stride, padding=padd)),\n",
        "    self.add_module('norm', nn.BatchNorm2d(out_channel)),\n",
        "    self.add_module('LeakyRelu', nn.LeakyReLU(0.2, inplace=True))\n",
        "\n",
        "def weights_init(m):\n",
        "  classname = m.__class__.__name__\n",
        "  if classname.find('Conv2d') != -1:\n",
        "    m.weight.data.normal_(0.0, 0.02)\n",
        "  elif classname.find('Norm') != -1:\n",
        "    # TODO: Verify that this code initializes to zero mean and unit variance.\n",
        "    # The normal_(1.0, 0.01) is confusing because it looks like unit mean and 0.01 variance?\n",
        "    # https://forums.fast.ai/t/how-is-batch-norm-initialized/39818\n",
        "    m.weight.data.normal_(1.0, 0.01)\n",
        "    m.bias.data.fill_(0)\n",
        "\n",
        "class WDiscriminator2(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(WDiscriminator2, self).__init__()\n",
        "        self.is_cuda = torch.cuda.is_available()\n",
        "        N = int(opt.nfc)\n",
        "        self.head = ConvBlock(opt.nc_im,N,opt.ker_size,opt.padd_size,1)\n",
        "        self.body = nn.Sequential()\n",
        "        for i in range(opt.num_layer-2):\n",
        "            N = int(opt.nfc/pow(2,(i+1)))\n",
        "            block = ConvBlock(max(2*N,opt.min_nfc),max(N,opt.min_nfc),opt.ker_size,opt.padd_size,1)\n",
        "            self.body.add_module('block%d'%(i+1),block)\n",
        "        self.tail = nn.Conv2d(max(N,opt.min_nfc),1,kernel_size=opt.ker_size,stride=1,padding=opt.padd_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.head(x)\n",
        "        x = self.body(x)\n",
        "        x = self.tail(x)\n",
        "        return x\n",
        "\n",
        "class GeneratorConcatSkip2CleanAdd2(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(GeneratorConcatSkip2CleanAdd2, self).__init__()\n",
        "        self.is_cuda = torch.cuda.is_available()\n",
        "        N = opt.nfc\n",
        "        self.head = ConvBlock(opt.nc_im,N,opt.ker_size,opt.padd_size,1) #GenConvTransBlock(opt.nc_z,N,opt.ker_size,opt.padd_size,opt.stride)\n",
        "        self.body = nn.Sequential()\n",
        "        for i in range(opt.num_layer-2):\n",
        "            N = int(opt.nfc/pow(2,(i+1)))\n",
        "            block = ConvBlock(max(2*N,opt.min_nfc),max(N,opt.min_nfc),opt.ker_size,opt.padd_size,1)\n",
        "            self.body.add_module('block%d'%(i+1),block)\n",
        "        self.tail = nn.Sequential(\n",
        "            nn.Conv2d(max(N,opt.min_nfc),opt.nc_im,kernel_size=opt.ker_size,stride =1,padding=opt.padd_size),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self,x,y):\n",
        "        x = self.head(x)\n",
        "        x = self.body(x)\n",
        "        x = self.tail(x)\n",
        "        # NOTE: Are they downsampling/upsampling here?\n",
        "        ind = int((y.shape[2]-x.shape[2])/2)\n",
        "        y = y[:,:,ind:(y.shape[2]-ind),ind:(y.shape[3]-ind)]\n",
        "        return x+y\n",
        "\n",
        "class DummyOpt:\n",
        "  def __init__(self):\n",
        "    self.nfc = 32\n",
        "    self.nc_im = 3\n",
        "    self.ker_size = 3\n",
        "    self.padd_size = 1\n",
        "    self.num_layer = 5\n",
        "    self.min_nfc = 3\n",
        "opt_example = DummyOpt()\n",
        "D_example = WDiscriminator2(opt_example)\n",
        "G_example = GeneratorConcatSkip2CleanAdd2(opt_example)\n",
        "\n",
        "print(D_example)\n",
        "print(G_example)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jpfpY2_kFeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/SinGAN\n",
        "!git checkout experimental\n",
        "![ -d TrainedModels ] && rm -r TrainedModels\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Import help functions from SinGAN\n",
        "import config\n",
        "from config import get_arguments\n",
        "from SinGAN.manipulate import *\n",
        "from SinGAN.training import *\n",
        "import SinGAN.functions as functions\n",
        "\n",
        "print('Implement SinGAN here...')\n",
        "\n",
        "# Replace the specific functions we want to reimplement\n",
        "SinGAN.training.train_single_scale = train_single_scale2\n",
        "SinGAN.models.WDiscriminator = WDiscriminator2\n",
        "SinGAN.models.GeneratorConcatSkip2CleanAdd = GeneratorConcatSkip2CleanAdd2\n",
        "\n",
        "del sys.argv[:]\n",
        "sys.argv.append('main_train.py')\n",
        "\n",
        "parser = get_arguments()\n",
        "parser.add_argument('--input_dir', help='input image dir', default='Input/Images')\n",
        "parser.add_argument('--input_name', help='input image name', default='birds.png')\n",
        "parser.add_argument('--mode', help='task to be done', default='train')\n",
        "\n",
        "opt = parser.parse_args()\n",
        "opt = functions.post_config(opt)\n",
        "\n",
        "Gs = []\n",
        "Zs = []\n",
        "reals = []\n",
        "NoiseAmp = []\n",
        "dir2save = functions.generate_dir2save(opt)\n",
        "\n",
        "if os.path.exists(dir2save):\n",
        "  print('trained model already exists: {}'.format(dir2save))\n",
        "else:\n",
        "  try:\n",
        "    os.makedirs(dir2save)\n",
        "  except OSError:\n",
        "    pass\n",
        "  real = functions.read_image(opt)\n",
        "  functions.adjust_scales2image(real, opt)\n",
        "  train(opt, Gs, Zs, reals, NoiseAmp)\n",
        "  SinGAN_generate(Gs, Zs, reals, NoiseAmp, opt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lef1W2LbbvbX",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation: Let's generate some SinGAN images and look at the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxiwGa6zbtIe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 random_samples.py --input_name birds.png --mode random_samples_arbitrary_sizes --scale_h 1 --scale_v 1\n",
        "!ls\n",
        "!ls -l Output/RandomSamples/birds\n",
        "!ls -l Output/RandomSamples/birds/gen_start_scale=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzqW9aoqbu46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print('original image')\n",
        "original_img_path = 'Input/Images/birds.png'\n",
        "img = cv2.imread(original_img_path)\n",
        "cv2_imshow(img)\n",
        "\n",
        "# Get generated images\n",
        "img_paths = glob.glob('Output/RandomSamples/birds/gen_start_scale=0/*.png')\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[0])\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[1])\n",
        "cv2_imshow(img)\n",
        "\n",
        "print('random sample')\n",
        "img = cv2.imread(img_paths[2])\n",
        "cv2_imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}